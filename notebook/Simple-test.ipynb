{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09d24b5c-8d35-4992-be38-67842c3e308d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2d1a031-1dc5-42e4-8a0e-7f2630f413d0",
   "metadata": {},
   "source": [
    "Univariate Gaussian (MeanField and FullRank are equivalent)\n",
    "\n",
    "    Model:\n",
    "\n",
    "        Prior: μ ~ N(μ₀, σ₀²)\n",
    "\n",
    "        Likelihood: y | μ ~ N(μ, σ²) (with σ known)\n",
    "\n",
    "    True Posterior:\n",
    "\n",
    "        μ | y ~ N(μₙ, σₙ²), where:\n",
    "\n",
    "            μₙ = (μ₀/σ₀² + n ȳ/σ²) / (1/σ₀² + n/σ²)\n",
    "\n",
    "            σₙ² = 1 / (1/σ₀² + n/σ²)\n",
    "\n",
    "    ADVI Result:\n",
    "\n",
    "        MeanField and FullRank should both recover μₙ and σₙ².\n",
    "\n",
    "        ELBO should equal the true log marginal likelihood.\n",
    "\n",
    "\n",
    "Example 1: 1D Gaussian (Analytical Results)\n",
    "\n",
    "Let μ₀ = 0, σ₀² = 1, σ² = 1, and data y = [1.0] (n=1):\n",
    "\n",
    "    True Posterior:\n",
    "\n",
    "        μₙ = 0.5, σₙ² = 0.5\n",
    "\n",
    "    Log Marginal Likelihood:\n",
    "    python\n",
    "\n",
    "log_p_y = -0.5 * (np.log(4 * np.pi) + 0.5) ≈ -1.2655 - 0.25 = -1.5155\n",
    "\n",
    "ADVI Check:\n",
    "\n",
    "    Variational mean ≈ 0.5, variance ≈ 0.5.\n",
    "\n",
    "    ELBO ≈ -1.5155."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e686e899-5aa5-48c1-a2ad-4009464ac040",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LowRankGuide:\n",
      "mu 4.97e-01 , var 5.04e-01 , elbo -1.51e+00\n",
      "FullRankGuide:\n",
      "mu 5.00e-01 , var 4.99e-01 , elbo -1.52e+00\n",
      "MeanFieldGuide:\n",
      "mu 5.00e-01 , var 4.99e-01 , elbo -1.52e+00\n",
      "MAPGuide:\n",
      "mu 5.00e-01 , var 0.00e+00 , elbo -2.09e+00\n",
      "LaplaceApproxGuide:\n",
      "mu 5.00e-01 , var 5.00e-01 , elbo -1.34e+00\n"
     ]
    }
   ],
   "source": [
    "from jax.scipy.stats import norm,beta,expon\n",
    "from jax_advi.advi import optimize_advi\n",
    "from jax_advi.constraints import constrain_range_stable,constrain_sigmoid_stable,constrain_exp\n",
    "from jax_advi.guide import LowRankGuide , MeanFieldGuide,FullRankGuide, VariationalGuide,MAPGuide,LaplaceApproxGuide\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "from functools import partial\n",
    "jax.config.update('jax_enable_x64', True)\n",
    "\n",
    "\n",
    "def generate_shapes_and_constraints():\n",
    "    theta_shapes = {'mu': (1,)}\n",
    "    theta_constraints = {}\n",
    "    return theta_shapes,theta_constraints\n",
    "def log_prior_fun(params,mup=0,sigmap=1):\n",
    "    return norm.logpdf(params[\"mu\"],mup,sigmap)\n",
    "\n",
    "def log_lik_fun(params,data,sigma=1): #Assume sicma knowm\n",
    "    return jnp.sum(norm.logpdf(data, params[\"mu\"], sigma))\n",
    "\n",
    "data= jnp.array([1.])\n",
    "M = 100_000\n",
    "opt_method = \"L-BFGS-B\"\n",
    "verbose = True\n",
    "\n",
    "for guide in [LowRankGuide(1),FullRankGuide(),MeanFieldGuide(),LaplaceApproxGuide(),MAPGuide()][:]:\n",
    "#guide = FullRankGuide()  # OptiGuide , FullRankGui\n",
    "\n",
    "        # Initialize optimizer\n",
    "\n",
    "    curried_lik = jax.jit(partial(log_lik_fun, data=data))\n",
    "\n",
    "    curried_prior  = log_prior_fun\n",
    "\n",
    "    theta_shapes,theta_constraints = generate_shapes_and_constraints()\n",
    "\n",
    "    result = optimize_advi(\n",
    "        theta_shapes,\n",
    "        log_prior_fun=curried_prior,\n",
    "        log_lik_fun=curried_lik,\n",
    "        constrain_fun_dict=theta_constraints,\n",
    "        verbose=False,\n",
    "        guide=guide, \n",
    "        M=M ,  # Number of MC samples\n",
    "        opt_method=opt_method,\n",
    "        n_draws=1_000_000\n",
    "        #M=10\n",
    "    )\n",
    "    posterior_mu_sample = jnp.mean(result[\"draws\"][\"mu\"])\n",
    "    posterior_var_sample = jnp.std(result[\"draws\"][\"mu\"])**2\n",
    "    elbo = result[\"elbo\"]\n",
    "    #print(result[\"guide\"])\n",
    "    print(f\"{guide.name}:\")\n",
    "    print(f\"mu {posterior_mu_sample:.2e} , var {posterior_var_sample:.2e} , elbo {elbo:.2e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mathmodrep]",
   "language": "python",
   "name": "conda-env-mathmodrep-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
